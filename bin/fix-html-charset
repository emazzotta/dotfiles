#!/usr/bin/env python3
from dataclasses import dataclass, field
from enum import Enum, auto
from pathlib import Path
from typing import Final
import argparse
import logging
import re
import sys


BACKUP_SUFFIX: Final = ".backup"
DEFAULT_TARGET_DIR: Final = "."

CHARSET_META_PATTERN: Final = re.compile(
    r'<meta\s+charset\s*=\s*["\']?([^"\'\s>]+)["\']?\s*/?\s*>',
    re.IGNORECASE
)

CHARSET_CONTENT_PATTERN: Final = re.compile(
    r'(<meta\s+http-equiv\s*=\s*["\']?Content-Type["\']?\s+content\s*=\s*["\']?)([^;]+)(;\s*charset=)([^"\'\s>]+)(["\']?\s*/?\s*>)',
    re.IGNORECASE
)

TITLE_TAG_PATTERN: Final = re.compile(r'(\s*)<title[^>]*>', re.IGNORECASE)


class ProcessingStatus(Enum):
    FIXED = auto()
    SKIPPED = auto()
    FAILED = auto()


@dataclass
class ProcessingResult:
    status: ProcessingStatus
    message: str = ""


@dataclass
class ProcessingSummary:
    total: int = 0
    fixed: int = 0
    skipped: int = 0
    failed: int = 0
    failed_files: list[str] = field(default_factory=list)


def setup_logging(verbose: bool) -> None:
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        format="[%(asctime)s] %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
        level=level,
    )


def validate_directory(directory: Path) -> None:
    if not directory.exists():
        raise FileNotFoundError(f"Directory not found: {directory}")
    if not directory.is_dir():
        raise NotADirectoryError(f"Not a directory: {directory}")


def find_html_files(directory: Path) -> list[Path]:
    return sorted(directory.rglob("*.html"))


def has_charset_declaration(content: str) -> bool:
    if CHARSET_META_PATTERN.search(content):
        return True
    if CHARSET_CONTENT_PATTERN.search(content):
        return True
    return False


def normalize_charset_meta(content: str) -> tuple[str, bool]:
    changed = False

    def replace_charset_meta(match: re.Match) -> str:
        nonlocal changed
        current_charset = match.group(1)
        if current_charset.upper() != "UTF-8":
            changed = True
            return '<meta charset="UTF-8">'
        return match.group(0)

    content = CHARSET_META_PATTERN.sub(replace_charset_meta, content)
    return content, changed


def normalize_charset_content(content: str) -> tuple[str, bool]:
    changed = False

    def replace_charset_content(match: re.Match) -> str:
        nonlocal changed
        current_charset = match.group(4)
        if current_charset.upper() != "UTF-8":
            changed = True
            return match.group(1) + match.group(2) + match.group(3) + "UTF-8" + match.group(5)
        return match.group(0)

    content = CHARSET_CONTENT_PATTERN.sub(replace_charset_content, content)
    return content, changed


def add_charset_declaration(content: str) -> str:
    title_match = TITLE_TAG_PATTERN.search(content)

    if title_match:
        whitespace = title_match.group(1)
        indent = whitespace.split('\n')[-1]

        insert_pos = title_match.start()
        meta_and_spacing = f'\n{indent}<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">\n{indent}'

        return content[:insert_pos] + meta_and_spacing + content[insert_pos + len(whitespace):]
    else:
        doctype_match = re.search(r'<!DOCTYPE[^>]*>\s*', content, re.IGNORECASE)
        if doctype_match:
            insert_pos = doctype_match.end()
            return content[:insert_pos] + '<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">\n' + content[insert_pos:]
        else:
            return '<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">\n' + content


def fix_html_charset(content: str) -> tuple[str, list[str]]:
    changes = []

    charset_meta_matches = list(CHARSET_META_PATTERN.finditer(content))
    charset_content_matches = list(CHARSET_CONTENT_PATTERN.finditer(content))

    all_matches = []
    for match in charset_meta_matches:
        all_matches.append(("meta", match))
    for match in charset_content_matches:
        all_matches.append(("content", match))

    all_matches.sort(key=lambda x: x[1].start())

    if not all_matches:
        content = add_charset_declaration(content)
        changes.append("added charset UTF-8")
        return content, changes

    first_match_type, first_match = all_matches[0]
    first_start = first_match.start()
    first_end = first_match.end()

    if first_match_type == "meta":
        current_charset = first_match.group(1)
        if current_charset.upper() != "UTF-8":
            first_replacement = '<meta charset="UTF-8">'
            changes.append("normalized charset to UTF-8")
        else:
            first_replacement = first_match.group(0)
    else:
        current_charset = first_match.group(4)
        if current_charset.upper() != "UTF-8":
            first_replacement = first_match.group(1) + first_match.group(2) + first_match.group(3) + "UTF-8" + first_match.group(5)
            changes.append("normalized charset to UTF-8")
        else:
            first_replacement = first_match.group(0)

    if len(all_matches) > 1:
        parts = [content[:first_start], first_replacement]
        prev_end = first_end

        duplicates = all_matches[1:]
        for _, dup_match in duplicates:
            parts.append(content[prev_end:dup_match.start()])
            prev_end = dup_match.end()

        parts.append(content[prev_end:])
        content = "".join(parts)

        changes.append(f"removed {len(duplicates)} duplicate charset declaration(s)")
    else:
        content = content[:first_start] + first_replacement + content[first_end:]

    return content, changes


def create_backup(file_path: Path) -> Path:
    backup_path = Path(str(file_path) + BACKUP_SUFFIX)

    if backup_path.exists():
        raise FileExistsError(f"Backup already exists: {backup_path}")

    backup_path.write_bytes(file_path.read_bytes())
    logging.debug(f"Created backup: {backup_path}")

    return backup_path


def restore_from_backup(file_path: Path, backup_path: Path) -> None:
    logging.warning(f"Restoring from backup: {backup_path}")
    file_path.write_bytes(backup_path.read_bytes())


def remove_backup(backup_path: Path) -> None:
    backup_path.unlink()
    logging.debug(f"Deleted backup: {backup_path}")


def process_file(file_path: Path, dry_run: bool) -> ProcessingResult:
    logging.debug(f"Processing: {file_path}")

    try:
        original_content = file_path.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        return ProcessingResult(
            ProcessingStatus.FAILED, "Failed to read as UTF-8"
        )
    except Exception as e:
        return ProcessingResult(ProcessingStatus.FAILED, f"Read error: {e}")

    try:
        fixed_content, changes = fix_html_charset(original_content)
    except Exception as e:
        return ProcessingResult(ProcessingStatus.FAILED, f"Processing error: {e}")

    if not changes:
        logging.debug(f"No changes needed: {file_path}")
        return ProcessingResult(ProcessingStatus.SKIPPED, "No changes needed")

    if dry_run:
        logging.info(f"[DRY RUN] Would fix ({', '.join(changes)}): {file_path}")
        return ProcessingResult(ProcessingStatus.FIXED, "Would be fixed")

    backup_path = None
    try:
        backup_path = create_backup(file_path)

        temp_path = file_path.with_suffix(file_path.suffix + ".tmp")
        temp_path.write_text(fixed_content, encoding="utf-8")

        temp_path.replace(file_path)

        remove_backup(backup_path)

        logging.info(f"Fixed ({', '.join(changes)}): {file_path}")
        return ProcessingResult(ProcessingStatus.FIXED, "Successfully fixed")

    except Exception as e:
        if backup_path and backup_path.exists():
            restore_from_backup(file_path, backup_path)
        return ProcessingResult(ProcessingStatus.FAILED, f"Write error: {e}")


def process_directory(directory: Path, dry_run: bool) -> ProcessingSummary:
    summary = ProcessingSummary()

    html_files = find_html_files(directory)

    for file_path in html_files:
        summary.total += 1
        result = process_file(file_path, dry_run)

        if result.status == ProcessingStatus.FIXED:
            summary.fixed += 1
        elif result.status == ProcessingStatus.SKIPPED:
            summary.skipped += 1
        elif result.status == ProcessingStatus.FAILED:
            summary.failed += 1
            summary.failed_files.append(str(file_path))
            logging.error(f"Failed: {file_path} - {result.message}")

    return summary


def print_summary(summary: ProcessingSummary, dry_run: bool) -> None:
    print()
    logging.info("Summary:")
    logging.info(f"  Total files: {summary.total}")

    if dry_run:
        logging.info(f"  Would fix: {summary.fixed}")
        logging.info(f"  Would skip: {summary.skipped}")
        logging.info("  [DRY RUN] No changes made")
    else:
        logging.info(f"  Fixed: {summary.fixed}")
        logging.info(f"  Skipped: {summary.skipped}")
        logging.info(f"  Failed: {summary.failed}")

    if summary.failed_files:
        logging.info("  Failed files:")
        for failed_file in summary.failed_files:
            logging.info(f"    - {failed_file}")


def build_argument_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        description="Fix HTML charset declarations: add UTF-8 charset if missing or normalize existing to UTF-8",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s
  %(prog)s --dry-run
  %(prog)s --dir /path/to/html/files
  %(prog)s -n -v --dir ../help/src/main/resources/de
        """,
    )

    parser.add_argument(
        "-d",
        "--dir",
        type=Path,
        default=Path(DEFAULT_TARGET_DIR),
        help=f"Target directory (default: {DEFAULT_TARGET_DIR})",
    )
    parser.add_argument(
        "-n",
        "--dry-run",
        action="store_true",
        help="Show what would be done without making changes",
    )
    parser.add_argument(
        "-v", "--verbose", action="store_true", help="Show detailed processing information"
    )

    return parser


def main() -> int:
    parser = build_argument_parser()
    args = parser.parse_args()

    setup_logging(args.verbose)

    if args.dry_run:
        logging.info("Running in DRY RUN mode")

    try:
        validate_directory(args.dir)
    except (FileNotFoundError, NotADirectoryError, PermissionError) as e:
        logging.error(str(e))
        return 1

    logging.info(f"Scanning directory: {args.dir}")
    summary = process_directory(args.dir, args.dry_run)

    print_summary(summary, args.dry_run)
    logging.info("Done")

    return 0 if summary.failed == 0 else 1


if __name__ == "__main__":
    sys.exit(main())
